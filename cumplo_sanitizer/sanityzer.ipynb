{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "\n",
    "from src import cumplo_core as cumplo_core\n",
    "from src import some_utils as utls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebooks will cache the scripts,\n",
    "# but this allows for automatic reloading of updated scripts,\n",
    "# eliminating the need to manually reload each time.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Import data:</h5>\n",
    "\n",
    "We will read the flow and movements files to work with them\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data in/out path...\n",
    "data_in_folder = \"./data_in/\"\n",
    "data_out_folder = \"./data_out/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movs_file_path = utls.get_most_recent_filename(data_in_folder, \"Resumen de movimientos - \", \"xls\")\n",
    "flows_file_path = utls.get_most_recent_filename(data_in_folder, \"Resumen de flujos - \", \"xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_df = pd.read_excel(flows_file_path)\n",
    "movs_df = pd.read_excel(movs_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Clean and transform data:</h5>\n",
    "\n",
    "We will read the flow and movements files to work with them\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flows:\n",
    "\n",
    "# Remove last 5 rows, that are Label cells\n",
    "flows_df = flows_df[:-5]\n",
    "\n",
    "# Convert Ids to strings w/o decimals\n",
    "flows_df[\"ID\"] = flows_df[\"ID\"].apply(int).apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movements:\n",
    "\n",
    "# Fill NAs\n",
    "movs_df = movs_df.fillna(0)\n",
    "\n",
    "# Remove rows that Descripción is 'Abono a Saldo Cumplo' or 'Retiro de Saldo Cumplo'\n",
    "movs_df = movs_df.query(\n",
    "    'Descripción != \"Abono a Saldo Cumplo\" & Descripción != \"Retiro de saldo Cumplo\"'\n",
    ")\n",
    "\n",
    "# keep only meaningful movements, Cargo or Abono > 0...\n",
    "movs_df = movs_df.query(\"Cargo > 0 | Abono > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Look for RemateID on all movements:</h5>\n",
    "\n",
    "We are going to create a new column called `Solicitud` , where we are going to extract the 'relevant' info from `Descripción` column.\n",
    "\n",
    "This is going to be used later to group investments by `RemateID`.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern 1: 'solicitud: (\\w.+)'\n",
    "# Liberación de Puntos Cumplo Retenidos, solicitud: Prepago crédito Cumplo contra línea capital de trabajo\n",
    "# Retención de Puntos Cumplo, solicitud: Prepago crédito Cumplo contra línea capital de trabajo\n",
    "# Retención de Puntos Cumplo, solicitud: Capital de trabajo Linea Comex\n",
    "# Devolución de fondos por crédito no concretado, solicitud: Crédito Kio Solutions\n",
    "# Pago de inversión, solicitud: Crédito Kio Solutions\n",
    "pattern1 = \"solicitud: (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern1, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 2: 'solicitud \"(\\w.+)\".'\n",
    "# Devolución de Puntos por solicitud \"Capital de trabajo Linea Comex\".\n",
    "pattern2 = 'solicitud \"(\\w.+)\".'\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern2, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 3: 'Reajuste puntos Cumplo por solicitud (\\w.+)'\n",
    "# Reajuste puntos Cumplo por solicitud 73278\n",
    "pattern3 = \"Reajuste puntos Cumplo por solicitud (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern3, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 4: 'regularizacion saldo cumplo operacion (\\w.+)'\n",
    "# regularizacion saldo cumplo operacion 70500\n",
    "pattern4 = \"regularizacion saldo cumplo operacion (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern4, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 5: 'reembolso puntos cumplo operación (\\w.+)'\n",
    "# reembolso puntos cumplo operación 73014\n",
    "pattern5 = \"reembolso puntos cumplo operación (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern5, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 6: 'Devolución de fondos por crédito no concretado, solicitud: (\\w.+)'\n",
    "# Devolución de fondos por crédito no concretado, solicitud: Capital de trabajo Linea Comex\n",
    "pattern6 = \"Devolución de fondos por crédito no concretado, solicitud: (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern6, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 7: 'regularizacion saldo cumplo (3cuotas) operación (\\w.+)'\n",
    "# regularizacion saldo cumplo (3cuotas) operación 71701\n",
    "pattern7 = \"regularizacion saldo cumplo \\(3cuotas\\) operación (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern7, \"Descripción\", \"Solicitud\")\n",
    "\n",
    "# pattern 8: 'regularizacion saldo cumplo, capital faltante operación (\\w.+)'\n",
    "# regularizacion saldo cumplo, capital faltante operación 71701\n",
    "pattern8 = \"regularizacion saldo cumplo, capital faltante operación (\\w.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern8, \"Descripción\", \"Solicitud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movements, get the ID of the investment on a new column\n",
    "# First a 'quick and dirty' approach that works for all 'modern' nomeclature\n",
    "movs_df[\"RemateID\"] = movs_df[\"Solicitud\"].str.split().str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set non-numeric RemateID as NA\n",
    "mask = ~pd.to_numeric(movs_df[\"RemateID\"], errors=\"coerce\").notnull()\n",
    "movs_df.loc[mask, \"RemateID\"] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the rest of the investments where we weren't able to find its ID,\n",
    "# we will use the info from flows...\n",
    "\n",
    "# First we need to know which ids we already have;\n",
    "known_ids = movs_df.query(\"RemateID.notna()\")[\"RemateID\"].unique()\n",
    "\n",
    "# And we use that to only go through the unknown ids...\n",
    "unknown_id_mask = ~flows_df[\"ID\"].isin(known_ids)\n",
    "\n",
    "\n",
    "for index, row in flows_df[unknown_id_mask].iterrows():\n",
    "    flow_id = row[\"ID\"]\n",
    "    flow_solicitud = row[\"Solicitud\"]\n",
    "    mask = movs_df[\"Solicitud\"].str.startswith(flow_solicitud, na=False)\n",
    "\n",
    "    if not mask.any():\n",
    "        # We can't find any !!\n",
    "        desc = movs_df[\"Solicitud\"]\n",
    "\n",
    "        print(f\"We can't find any match for: Index: [{index}] id:[{flow_id}]- [{flow_solicitud}]\")\n",
    "        continue\n",
    "\n",
    "    # display(f'we found;  {current_id}  [{index}] - [{current_solicitud}]')\n",
    "    movs_df.loc[mask, \"RemateID\"] = str(int(flow_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opposite approach;\n",
    "# Since there are weird edge cases;\n",
    "# Like, description in flows that has more info than in movements\n",
    "# our previous search and assignment would fail in some cases;\n",
    "# For example we have:\n",
    "# in flows_df Solicitud: \"Crédito Más Ingenieria 23028\"\n",
    "# and in movs_df Solicitud:\"Crédito Más Ingenieria \"\n",
    "# But for this we will only use the ids that are are still not assigned\n",
    "known_ids = set(movs_df.query(\"RemateID.notna()\")[\"RemateID\"])\n",
    "flow_ids = set(flows_df[\"ID\"])\n",
    "unassigned_flow_ids = flow_ids - known_ids\n",
    "\n",
    "unnasigned_ids_mask = flows_df[\"ID\"].isin(unassigned_flow_ids)\n",
    "unassigned_df = flows_df[unnasigned_ids_mask]\n",
    "\n",
    "# Skip all those movs where we already know the id\n",
    "na_ids_mask = movs_df[\"RemateID\"].isna()\n",
    "# Also,s kip all those movs where 'Solicitud' is na\n",
    "na_solicitus_mask = movs_df[\"Solicitud\"].notna()\n",
    "\n",
    "# Get ID using data on movs_df\n",
    "for index, row in movs_df[na_ids_mask & na_solicitus_mask].iterrows():\n",
    "    current_solicitud = row[\"Solicitud\"]\n",
    "\n",
    "    mask = unassigned_df[\"Solicitud\"].str.startswith(current_solicitud, na=False)\n",
    "    if not mask.any():\n",
    "        # We can't find any !!\n",
    "        print(f\"We can't find any match for: Index: [{index}] - [{current_solicitud}]\")\n",
    "        continue\n",
    "\n",
    "    current_id = unassigned_df[mask][\"ID\"].values[0]\n",
    "    # print(f'we found; for [{index}] - [{current_solicitud}]')\n",
    "    movs_df.loc[index, \"RemateID\"] = str(int(current_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Extract Actors:</h5>\n",
    "\n",
    "On `Solicitud` column most of the time we have enough info to extract the `Actor` behind the operation.\n",
    "\n",
    "This would be useful later to get the RemateID.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Actor names from Solicitud\n",
    "\n",
    "# pattern1: 'Credito (.+) (\\d+)' # No accent mark!\n",
    "# Credito COMERCIAL 2050 SPA 24494 >> 'COMERCIAL 2050 SPA'\n",
    "# Credito INMOBILIARIA JUAN CARLOS VALDEBENITO ORTIZ E.I.R.L 23356, parte II >> 'INMOBILIARIA JUAN CARLOS VALDEBENITO ORTIZ E.I.R.L'\n",
    "pattern1 = \"Credito (.+) (\\d+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern1, \"Solicitud\", \"Actor\")\n",
    "\n",
    "# pattern2: '^Crédito (.+)' # Accent mark!\n",
    "# Crédito eHS SpA. >> 'eHS SpA.' # tilde\n",
    "# Crédito Notebookcenter >> 'Notebookcenter'\n",
    "# Crédito Buscalibre.com >> 'Buscalibre.com'\n",
    "# Crédito Corto Plazo II: Renovación de línea de construcción >> 'Corto Plazo II: Renovación de línea de construcción'\n",
    "pattern2 = \"^Crédito (.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern2, \"Solicitud\", \"Actor\")\n",
    "\n",
    "# pattern3: '^Credito (.+)' # No accent mark (and no investment ID at the end...)\n",
    "# Credito Green Logistic\n",
    "# Credito Ambrosio Torresilla\n",
    "pattern3 = \"^Credito (.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern3, \"Solicitud\", \"Actor\")\n",
    "\n",
    "# pattern4: '(.+): .*'\n",
    "# BAXIS EIRL: Crédito empresa 80% garantizado >> 'BAXIS EIRL'\n",
    "# INMOBILIARIA JUAN CARLOS VALDEBENITO ORTIZ E.I.R.L: Crédito Nº2 empresa Cero Cupón 100% garantizado SuAval >> 'INMOBILIARIA JUAN CARLOS VALDEBENITO ORTIZ E.I.R.L'\n",
    "pattern4 = \"(.+): .*\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern4, \"Solicitud\", \"Actor\")\n",
    "\n",
    "# Now we have just all the rest, but avoid the 'only numbers'\n",
    "# pattern5: '^(?!\\d+$)(.+)'\n",
    "#   ^(?!\\d+$) => Do not match numbers until the end...\n",
    "#   (.+) => but we want all the other options...\n",
    "# 22474 - Solicitud Empresa >> '22474 - Solicitud Empresa'\n",
    "# Financiamento Febrero >> 'Financiamento Febrero'\n",
    "# 73278 >> na\n",
    "pattern5 = \"^(?!\\d+$)(.+)\"\n",
    "movs_df = utls.match_group_and_assign(movs_df, pattern5, \"Solicitud\", \"Actor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and replace spanish characters...\n",
    "movs_df[\"Actor\"] = movs_df[\"Actor\"].apply(utls.clean_spanish_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill the pending NA Actors\n",
    "# We have a 'complete' dframe of non-na Actors\n",
    "complete_df = movs_df.query(\"Actor.notna() & RemateID.notna()\")\n",
    "# We create a dictionary RemateID -> Actor\n",
    "dict_id_acts = dict(zip(complete_df[\"RemateID\"], complete_df[\"Actor\"]))\n",
    "# And we fill that using map\n",
    "movs_df[\"Actor\"] = movs_df[\"Actor\"].fillna(\n",
    "    movs_df[\"RemateID\"].map(dict_id_acts, na_action=\"ignore\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the last RemateID filling!\n",
    "# When RemateID is NA and Actor is not na, fill with Actor!\n",
    "\n",
    "# This works for the old-old investments\n",
    "movs_df[\"RemateID\"] = movs_df[\"RemateID\"].fillna(movs_df[\"Actor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Explore data:</h5>\n",
    "\n",
    "Explore all the Investments, grouped by RemateID\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumplo_core.explore_by_id(movs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Fix data:</h5>\n",
    "\n",
    "For some (another) weird reason, there are some investments that aren't completed on the movements flow.\n",
    "One way to spot them is to explore and check all those that have negative earnings.\n",
    "\n",
    "Then we will find:</br>\n",
    "\n",
    "- `a`. late, uncollectible, or active investments</br>\n",
    "- `b`. weird investment that must be fixed!</br>\n",
    "\n",
    "For `a` there is nothing that we need to do, but for `b` we have to apply a fix.\n",
    "\n",
    "It seems like the cause behind this is, cumplo has some issues exporting movements when there is more than one payment on the same date, or if the investment was cancelled, or others.\n",
    "\n",
    "I wasn't able to figure out a set of rules, so I had to inspect on the website (and sometimes check agains my bank account) to see what was going on.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_earning_ids = cumplo_core.find_negative_earning_ids(movs_df)\n",
    "print(f\"We found [{len(negative_earning_ids)}] investments with a negative balance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore negative investments; a.-late, uncollectible, active, or b.- incorrectly-recorded!\n",
    "# We are looking for the b.- incorrectly-recorded ids...\n",
    "cumplo_core.explore_by_id(movs_df, negative_earning_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Fix data:</h5>\n",
    "\n",
    "After looking for those special cases we come up with the following fix:\n",
    "\n",
    "For each one of these investments, we are going to add a new row with a `Abono` that fixes the total earnings.\n",
    "And we will store that data in a csv file called `fix_data.csv` located on `./data_in/`.\n",
    "\n",
    "---\n",
    "\n",
    "In my case, I had to check on cumplo.cl for each `weird` investment Id and see if the total earnings were equal to the actual earnings (or `Monto Recibido` ). When not, I calculated the difference and used it as an extra `Abono` to match the actual amount.\n",
    "\n",
    "For the date of the fix, I used the deposit date that you can find going to the investment's details (`Resumen de Pagos`).\n",
    "\n",
    "So at the end, I came up with a `fix_data.csv` similar to this:\n",
    "\n",
    "```csv\n",
    "    RemateID,Actor,Date_YYYY-MM-DD,Abono,Cargo\n",
    "    27555,avanza construccion ltda,2016-Sep-05,35409,0\n",
    "    27761,Comercial 2050,2016-Nov-11,9869,0\n",
    "    28106,avendaño y aranda,2016-May-05,52636,0\n",
    "    ...\n",
    "    33728,dolphins,2017-11-14,7700,0\n",
    "    ...\n",
    "    66019,Comercial 2050,2023-01-19,324095,0\n",
    "```\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply fix!\n",
    "fixdata_csv_path = path.join(data_in_folder, \"fix_data.csv\")\n",
    "movs_df = cumplo_core.insert_fix(movs_df, fixdata_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and replace spanish characters...\n",
    "movs_df[\"Actor\"] = movs_df[\"Actor\"].apply(utls.clean_spanish_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Classify data:</h5>\n",
    "\n",
    "Now we are going to clasiffy the investments in 4 categories;\n",
    "\n",
    "- `a`. Unexecuted (Investments that never were active. Funds were returned.)\n",
    "- `b`. Completed (Investments that are finish)\n",
    "- `c`. Active (Investments on track :), also investment with late payments but that are not older that some grace period...)\n",
    "- `d`. Uncollectible (Investments with pending payments that are older than some grace period...)\n",
    "\n",
    "We will get the ids of investments that are active, late, and uncollectible, directly from the flows excel file.\n",
    "Using the text color on the flows we can determine when a flow is late, expected, on-time, late-but-payed, etc...\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Classify active, late, and uncollectible:</h5>\n",
    "\n",
    "From the flows file we are going to extract the investments that are active, late, or uncollectible.\n",
    "\n",
    "Uncollectible will be all investments that are late more than `grace_period_days`.\n",
    "\n",
    "Also we will retrieve all the IDs that are not present in the flow file but exists in Movements.\n",
    "\n",
    "(If a investment was cancelled, or if a investment is too recent, the confirmation is pending this could be the case!)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use grace_period_days of 60 days (2 months)\n",
    "grace_period_days = 60\n",
    "flow_ids, active_ids, late_ids, uncollectible_ids = cumplo_core.extract_active_and_late_ids(\n",
    "    flows_file_path, grace_period_days\n",
    ")\n",
    "\n",
    "# Obtain all the ids that are not present in the flow file\n",
    "all_ids = movs_df[\"RemateID\"].unique()\n",
    "not_present_in_flows_ids = set(all_ids) - set(flow_ids)\n",
    "\n",
    "# Uncomment the next line; if you want to explore the ids that are not present in flows but in movements\n",
    "# We expect a lot of old and cancelled, and a few super recent investments.\n",
    "# The if Cargos-Abonos is close to zero, then we think that is a cancelled investment\n",
    "cumplo_core.explore_by_id(movs_df, not_present_in_flows_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Classify Just Payed:</h5>\n",
    "\n",
    "From the flows file we are going to extract the investments that are just payed (but not confirmed).\n",
    "\n",
    "For that we consider all of them that a.- Are not present in flow files, and b.- the difference between cargos and abonos is a considerable negative amount.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, investments that are 'Abonos' - 'Cargos' are a considerable\n",
    "# negative number and is not present in flows file can be considered as 'just payed'.\n",
    "\n",
    "# Instead of zero, we sill set a considerable_amount = 100000, which seems to be a good number...\n",
    "considerable_amount = 100000\n",
    "\n",
    "just_payed_ids = cumplo_core.extract_just_payed(\n",
    "    movs_df, not_present_in_flows_ids, considerable_amount\n",
    ")\n",
    "\n",
    "# Uncomment the next line; if you want to explore the ids classified as unexecuted\n",
    "cumplo_core.explore_by_id(movs_df, just_payed_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Classify Unexecuted:</h5>\n",
    "\n",
    "From the flows file we are going to extract the investments that weren't executed.\n",
    "\n",
    "For that we consider all of them where the difference between cargos and abonos is a despreciable amount.\n",
    "Taking into consideration the ids that are not registered on flows.\n",
    "\n",
    "For the just paye\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, investments that are 'Abonos' - 'Cargos' are zero (or close to zero)\n",
    "# can be considered as unexecuted.\n",
    "\n",
    "# Instead of zero, we sill set a despreciable_amount of 200, which seems to be a good number...\n",
    "despreciable_amount = 200\n",
    "unexecuted_ids = cumplo_core.extract_unexecuted(movs_df, despreciable_amount)\n",
    "\n",
    "# Uncomment the next line; if you want to explore the ids classified as unexecuted\n",
    "cumplo_core.explore_by_id(movs_df, unexecuted_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Remove unexecuted from extracted lists:</h5>\n",
    "\n",
    "We update our previous findings removing all the unexecuted ids.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ids removing unexecuted ids\n",
    "active_ids = list(set(active_ids) - set(unexecuted_ids))\n",
    "late_ids = list(set(late_ids) - set(unexecuted_ids))\n",
    "uncollectible_ids = list(set(uncollectible_ids) - set(unexecuted_ids))\n",
    "\n",
    "# Uncomment the next lines; if you want to explore the ids classified as active_ids, late_ids, and uncollectible_ids\n",
    "# cumplo_core.explore_by_id(movs_df, active_ids)\n",
    "# cumplo_core.explore_by_id(movs_df,late_ids)\n",
    "# cumplo_core.explore_by_id(movs_df, uncollectible_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Completed investments:</h5>\n",
    "\n",
    "All the ids that aren't `active`, `unexecuted`, `just_payed` or `late_but_collectibles` will be considered as `completed`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will state that all ids not active, unexecuted or late_but_collectibles are completed ids:\n",
    "late_but_collectibles = set(late_ids) - set(uncollectible_ids)\n",
    "\n",
    "# beware, we consider the uncollectibles as 'completed'. Cumplo.cl doesn't do this.\n",
    "completed_ids = (\n",
    "    set(all_ids)\n",
    "    - set(active_ids)\n",
    "    - set(unexecuted_ids)\n",
    "    - set(just_payed_ids)\n",
    "    - set(late_but_collectibles)\n",
    ")\n",
    "\n",
    "# Uncomment the next line; if you want to explore the ids classified as completed_ids\n",
    "# cumplo_core.explore_by_id(movs_df, completed_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Adjustments; Set Completed but not completely payed as Uncollectibles:</h5>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_mask = movs_df[\"RemateID\"].isin(completed_ids)\n",
    "completed_df = movs_df[completed_mask]\n",
    "\n",
    "grace_period_days_since_last_payment = 60\n",
    "completed_but_uncollectible_ids = cumplo_core.extract_uncollectibles(\n",
    "    completed_df, grace_period_days_since_last_payment\n",
    ")\n",
    "\n",
    "# Remove from completed\n",
    "completed_ids = list(set(completed_ids) - set(completed_but_uncollectible_ids))\n",
    "# Add to uncollectible_ids\n",
    "uncollectible_ids = list(set(uncollectible_ids) | set(completed_but_uncollectible_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Some stats:</h5>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats;\n",
    "print(\n",
    "    f\"Total of: [{len(all_ids):,}], Unexecuted: [{len(unexecuted_ids)}], Completed: [{len(completed_ids):,}]\"\n",
    ")\n",
    "print(\n",
    "    f\"Active: [{len(active_ids)}], Just Payed: [{len(just_payed_ids)}], Late: [{len(late_ids)}], Uncollectibles: [{len(uncollectible_ids)}]\"\n",
    ")\n",
    "print(f\"Late in the grace_period: [{(len(late_ids) - len(uncollectible_ids))}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Assign classification:</h5>\n",
    "\n",
    "We will create a new column called `Estado` to assign the classification of each investment.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movs_df[\"Estado\"] = \"NotAssigned\"\n",
    "\n",
    "# Unexecuted\n",
    "unexecuted_mask = movs_df[\"RemateID\"].isin(unexecuted_ids)\n",
    "movs_df.loc[unexecuted_mask, \"Estado\"] = \"Unexecuted\"\n",
    "\n",
    "# Completed\n",
    "completed_mask = movs_df[\"RemateID\"].isin(completed_ids)\n",
    "movs_df.loc[completed_mask, \"Estado\"] = \"Completed\"\n",
    "\n",
    "# Active: Active, Just Payed, or Late => Late are late, but Active!\n",
    "active_mask = movs_df[\"RemateID\"].isin(active_ids)\n",
    "late_mask = movs_df[\"RemateID\"].isin(late_ids)\n",
    "just_payed_mask = movs_df[\"RemateID\"].isin(just_payed_ids)\n",
    "movs_df.loc[late_mask | active_mask | just_payed_mask, \"Estado\"] = \"Active\"\n",
    "\n",
    "# Uncollectible\n",
    "uncollectible_mask = movs_df[\"RemateID\"].isin(uncollectible_ids)\n",
    "movs_df.loc[uncollectible_mask, \"Estado\"] = \"Uncollectible\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert\">\n",
    "<h5>Save data:</h5>\n",
    "\n",
    "Export dataframe to `data_out_folder`. <br>\n",
    "In our case: `./data_out/sanitized_and_classified.feather`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = path.join(data_out_folder, \"sanitized_and_classified.feather\")\n",
    "movs_df.to_feather(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
